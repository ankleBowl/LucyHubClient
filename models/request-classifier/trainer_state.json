{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3175,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015748031496062992,
      "grad_norm": 3.428516387939453,
      "learning_rate": 2.991496062992126e-05,
      "loss": 1.1417,
      "step": 10
    },
    {
      "epoch": 0.031496062992125984,
      "grad_norm": 3.0268144607543945,
      "learning_rate": 2.982047244094488e-05,
      "loss": 1.1067,
      "step": 20
    },
    {
      "epoch": 0.047244094488188976,
      "grad_norm": 2.757845640182495,
      "learning_rate": 2.9725984251968506e-05,
      "loss": 1.0861,
      "step": 30
    },
    {
      "epoch": 0.06299212598425197,
      "grad_norm": 2.9088175296783447,
      "learning_rate": 2.9631496062992127e-05,
      "loss": 1.0644,
      "step": 40
    },
    {
      "epoch": 0.07874015748031496,
      "grad_norm": 2.4314169883728027,
      "learning_rate": 2.953700787401575e-05,
      "loss": 1.0079,
      "step": 50
    },
    {
      "epoch": 0.09448818897637795,
      "grad_norm": 3.917673110961914,
      "learning_rate": 2.944251968503937e-05,
      "loss": 0.9693,
      "step": 60
    },
    {
      "epoch": 0.11023622047244094,
      "grad_norm": 2.590271472930908,
      "learning_rate": 2.9348031496062995e-05,
      "loss": 0.9284,
      "step": 70
    },
    {
      "epoch": 0.12598425196850394,
      "grad_norm": 3.1700117588043213,
      "learning_rate": 2.9253543307086616e-05,
      "loss": 0.8592,
      "step": 80
    },
    {
      "epoch": 0.14173228346456693,
      "grad_norm": 2.654003143310547,
      "learning_rate": 2.9159055118110237e-05,
      "loss": 0.8285,
      "step": 90
    },
    {
      "epoch": 0.15748031496062992,
      "grad_norm": 2.8693222999572754,
      "learning_rate": 2.906456692913386e-05,
      "loss": 0.7513,
      "step": 100
    },
    {
      "epoch": 0.1732283464566929,
      "grad_norm": 3.3580801486968994,
      "learning_rate": 2.8970078740157483e-05,
      "loss": 0.7359,
      "step": 110
    },
    {
      "epoch": 0.1889763779527559,
      "grad_norm": 3.4771718978881836,
      "learning_rate": 2.8875590551181104e-05,
      "loss": 0.7118,
      "step": 120
    },
    {
      "epoch": 0.2047244094488189,
      "grad_norm": 3.3536922931671143,
      "learning_rate": 2.8781102362204726e-05,
      "loss": 0.6552,
      "step": 130
    },
    {
      "epoch": 0.2204724409448819,
      "grad_norm": 2.3869006633758545,
      "learning_rate": 2.8686614173228347e-05,
      "loss": 0.6003,
      "step": 140
    },
    {
      "epoch": 0.23622047244094488,
      "grad_norm": 2.7778379917144775,
      "learning_rate": 2.859212598425197e-05,
      "loss": 0.6012,
      "step": 150
    },
    {
      "epoch": 0.25196850393700787,
      "grad_norm": 3.59889554977417,
      "learning_rate": 2.8497637795275593e-05,
      "loss": 0.602,
      "step": 160
    },
    {
      "epoch": 0.2677165354330709,
      "grad_norm": 3.9188950061798096,
      "learning_rate": 2.840314960629921e-05,
      "loss": 0.5354,
      "step": 170
    },
    {
      "epoch": 0.28346456692913385,
      "grad_norm": 2.8802497386932373,
      "learning_rate": 2.8308661417322835e-05,
      "loss": 0.5365,
      "step": 180
    },
    {
      "epoch": 0.2992125984251969,
      "grad_norm": 2.6102969646453857,
      "learning_rate": 2.8214173228346457e-05,
      "loss": 0.5308,
      "step": 190
    },
    {
      "epoch": 0.31496062992125984,
      "grad_norm": 1.86940336227417,
      "learning_rate": 2.811968503937008e-05,
      "loss": 0.484,
      "step": 200
    },
    {
      "epoch": 0.33070866141732286,
      "grad_norm": 3.9198904037475586,
      "learning_rate": 2.80251968503937e-05,
      "loss": 0.5256,
      "step": 210
    },
    {
      "epoch": 0.3464566929133858,
      "grad_norm": 3.6169748306274414,
      "learning_rate": 2.7930708661417324e-05,
      "loss": 0.5023,
      "step": 220
    },
    {
      "epoch": 0.36220472440944884,
      "grad_norm": 3.3290326595306396,
      "learning_rate": 2.7836220472440945e-05,
      "loss": 0.4557,
      "step": 230
    },
    {
      "epoch": 0.3779527559055118,
      "grad_norm": 2.1386306285858154,
      "learning_rate": 2.774173228346457e-05,
      "loss": 0.455,
      "step": 240
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 2.031090497970581,
      "learning_rate": 2.7647244094488188e-05,
      "loss": 0.4776,
      "step": 250
    },
    {
      "epoch": 0.4094488188976378,
      "grad_norm": 3.331540584564209,
      "learning_rate": 2.7552755905511812e-05,
      "loss": 0.4614,
      "step": 260
    },
    {
      "epoch": 0.4251968503937008,
      "grad_norm": 2.6067442893981934,
      "learning_rate": 2.7458267716535434e-05,
      "loss": 0.4444,
      "step": 270
    },
    {
      "epoch": 0.4409448818897638,
      "grad_norm": 2.4049150943756104,
      "learning_rate": 2.7363779527559058e-05,
      "loss": 0.4476,
      "step": 280
    },
    {
      "epoch": 0.4566929133858268,
      "grad_norm": 3.339679479598999,
      "learning_rate": 2.7269291338582676e-05,
      "loss": 0.4671,
      "step": 290
    },
    {
      "epoch": 0.47244094488188976,
      "grad_norm": 3.3810322284698486,
      "learning_rate": 2.71748031496063e-05,
      "loss": 0.3825,
      "step": 300
    },
    {
      "epoch": 0.4881889763779528,
      "grad_norm": 3.0762085914611816,
      "learning_rate": 2.7080314960629922e-05,
      "loss": 0.4445,
      "step": 310
    },
    {
      "epoch": 0.5039370078740157,
      "grad_norm": 5.705694198608398,
      "learning_rate": 2.6985826771653547e-05,
      "loss": 0.4079,
      "step": 320
    },
    {
      "epoch": 0.5196850393700787,
      "grad_norm": 2.6783130168914795,
      "learning_rate": 2.6891338582677165e-05,
      "loss": 0.4482,
      "step": 330
    },
    {
      "epoch": 0.5354330708661418,
      "grad_norm": 3.0992448329925537,
      "learning_rate": 2.679685039370079e-05,
      "loss": 0.3625,
      "step": 340
    },
    {
      "epoch": 0.5511811023622047,
      "grad_norm": 4.253981113433838,
      "learning_rate": 2.670236220472441e-05,
      "loss": 0.3984,
      "step": 350
    },
    {
      "epoch": 0.5669291338582677,
      "grad_norm": 4.100977897644043,
      "learning_rate": 2.6607874015748035e-05,
      "loss": 0.4061,
      "step": 360
    },
    {
      "epoch": 0.5826771653543307,
      "grad_norm": 5.309144973754883,
      "learning_rate": 2.6513385826771653e-05,
      "loss": 0.4115,
      "step": 370
    },
    {
      "epoch": 0.5984251968503937,
      "grad_norm": 3.1713571548461914,
      "learning_rate": 2.6418897637795278e-05,
      "loss": 0.4143,
      "step": 380
    },
    {
      "epoch": 0.6141732283464567,
      "grad_norm": 2.56449294090271,
      "learning_rate": 2.63244094488189e-05,
      "loss": 0.3931,
      "step": 390
    },
    {
      "epoch": 0.6299212598425197,
      "grad_norm": 3.0156667232513428,
      "learning_rate": 2.622992125984252e-05,
      "loss": 0.3808,
      "step": 400
    },
    {
      "epoch": 0.6456692913385826,
      "grad_norm": 2.4505693912506104,
      "learning_rate": 2.613543307086614e-05,
      "loss": 0.4579,
      "step": 410
    },
    {
      "epoch": 0.6614173228346457,
      "grad_norm": 2.8889665603637695,
      "learning_rate": 2.6040944881889763e-05,
      "loss": 0.4234,
      "step": 420
    },
    {
      "epoch": 0.6771653543307087,
      "grad_norm": 2.434915781021118,
      "learning_rate": 2.5946456692913388e-05,
      "loss": 0.3546,
      "step": 430
    },
    {
      "epoch": 0.6929133858267716,
      "grad_norm": 5.607664108276367,
      "learning_rate": 2.585196850393701e-05,
      "loss": 0.3357,
      "step": 440
    },
    {
      "epoch": 0.7086614173228346,
      "grad_norm": 3.8092613220214844,
      "learning_rate": 2.575748031496063e-05,
      "loss": 0.3375,
      "step": 450
    },
    {
      "epoch": 0.7244094488188977,
      "grad_norm": 1.398242712020874,
      "learning_rate": 2.566299212598425e-05,
      "loss": 0.3979,
      "step": 460
    },
    {
      "epoch": 0.7401574803149606,
      "grad_norm": 2.426699638366699,
      "learning_rate": 2.5568503937007876e-05,
      "loss": 0.3719,
      "step": 470
    },
    {
      "epoch": 0.7559055118110236,
      "grad_norm": 4.600984573364258,
      "learning_rate": 2.5474015748031497e-05,
      "loss": 0.3898,
      "step": 480
    },
    {
      "epoch": 0.7716535433070866,
      "grad_norm": 2.6719107627868652,
      "learning_rate": 2.537952755905512e-05,
      "loss": 0.3665,
      "step": 490
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 1.6714357137680054,
      "learning_rate": 2.528503937007874e-05,
      "loss": 0.3057,
      "step": 500
    },
    {
      "epoch": 0.8031496062992126,
      "grad_norm": 2.7091522216796875,
      "learning_rate": 2.5190551181102364e-05,
      "loss": 0.3571,
      "step": 510
    },
    {
      "epoch": 0.8188976377952756,
      "grad_norm": 3.299833059310913,
      "learning_rate": 2.5096062992125986e-05,
      "loss": 0.3789,
      "step": 520
    },
    {
      "epoch": 0.8346456692913385,
      "grad_norm": 4.0165886878967285,
      "learning_rate": 2.5001574803149607e-05,
      "loss": 0.3483,
      "step": 530
    },
    {
      "epoch": 0.8503937007874016,
      "grad_norm": 2.1151275634765625,
      "learning_rate": 2.4907086614173228e-05,
      "loss": 0.3566,
      "step": 540
    },
    {
      "epoch": 0.8661417322834646,
      "grad_norm": 4.361822128295898,
      "learning_rate": 2.4812598425196853e-05,
      "loss": 0.385,
      "step": 550
    },
    {
      "epoch": 0.8818897637795275,
      "grad_norm": 3.0267679691314697,
      "learning_rate": 2.4718110236220474e-05,
      "loss": 0.3536,
      "step": 560
    },
    {
      "epoch": 0.8976377952755905,
      "grad_norm": 6.57554292678833,
      "learning_rate": 2.4623622047244095e-05,
      "loss": 0.3777,
      "step": 570
    },
    {
      "epoch": 0.9133858267716536,
      "grad_norm": 3.2723238468170166,
      "learning_rate": 2.4529133858267717e-05,
      "loss": 0.3522,
      "step": 580
    },
    {
      "epoch": 0.9291338582677166,
      "grad_norm": 3.7426047325134277,
      "learning_rate": 2.443464566929134e-05,
      "loss": 0.3529,
      "step": 590
    },
    {
      "epoch": 0.9448818897637795,
      "grad_norm": 4.869752883911133,
      "learning_rate": 2.4340157480314963e-05,
      "loss": 0.3553,
      "step": 600
    },
    {
      "epoch": 0.9606299212598425,
      "grad_norm": 1.336206078529358,
      "learning_rate": 2.4245669291338584e-05,
      "loss": 0.3233,
      "step": 610
    },
    {
      "epoch": 0.9763779527559056,
      "grad_norm": 1.9302045106887817,
      "learning_rate": 2.4151181102362205e-05,
      "loss": 0.352,
      "step": 620
    },
    {
      "epoch": 0.9921259842519685,
      "grad_norm": 2.443314790725708,
      "learning_rate": 2.405669291338583e-05,
      "loss": 0.3236,
      "step": 630
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8574807806031933,
      "eval_loss": 0.3266325891017914,
      "eval_runtime": 13.5558,
      "eval_samples_per_second": 374.231,
      "eval_steps_per_second": 11.729,
      "step": 635
    },
    {
      "epoch": 1.0078740157480315,
      "grad_norm": 5.218774795532227,
      "learning_rate": 2.3962204724409448e-05,
      "loss": 0.379,
      "step": 640
    },
    {
      "epoch": 1.0236220472440944,
      "grad_norm": 3.0567750930786133,
      "learning_rate": 2.386771653543307e-05,
      "loss": 0.3431,
      "step": 650
    },
    {
      "epoch": 1.0393700787401574,
      "grad_norm": 2.4927926063537598,
      "learning_rate": 2.3773228346456694e-05,
      "loss": 0.3803,
      "step": 660
    },
    {
      "epoch": 1.0551181102362204,
      "grad_norm": 2.7432570457458496,
      "learning_rate": 2.3678740157480315e-05,
      "loss": 0.4037,
      "step": 670
    },
    {
      "epoch": 1.0708661417322836,
      "grad_norm": 4.530222415924072,
      "learning_rate": 2.3584251968503936e-05,
      "loss": 0.3663,
      "step": 680
    },
    {
      "epoch": 1.0866141732283465,
      "grad_norm": 2.874725580215454,
      "learning_rate": 2.3489763779527558e-05,
      "loss": 0.3167,
      "step": 690
    },
    {
      "epoch": 1.1023622047244095,
      "grad_norm": 3.548776865005493,
      "learning_rate": 2.3395275590551182e-05,
      "loss": 0.3357,
      "step": 700
    },
    {
      "epoch": 1.1181102362204725,
      "grad_norm": 2.5589065551757812,
      "learning_rate": 2.3300787401574803e-05,
      "loss": 0.3351,
      "step": 710
    },
    {
      "epoch": 1.1338582677165354,
      "grad_norm": 5.240231513977051,
      "learning_rate": 2.3206299212598425e-05,
      "loss": 0.3243,
      "step": 720
    },
    {
      "epoch": 1.1496062992125984,
      "grad_norm": 3.972430944442749,
      "learning_rate": 2.3111811023622046e-05,
      "loss": 0.3578,
      "step": 730
    },
    {
      "epoch": 1.1653543307086613,
      "grad_norm": 3.778884172439575,
      "learning_rate": 2.301732283464567e-05,
      "loss": 0.3254,
      "step": 740
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 3.7025723457336426,
      "learning_rate": 2.2922834645669292e-05,
      "loss": 0.3295,
      "step": 750
    },
    {
      "epoch": 1.1968503937007875,
      "grad_norm": 3.5448901653289795,
      "learning_rate": 2.2828346456692913e-05,
      "loss": 0.3615,
      "step": 760
    },
    {
      "epoch": 1.2125984251968505,
      "grad_norm": 3.6973373889923096,
      "learning_rate": 2.2733858267716534e-05,
      "loss": 0.3137,
      "step": 770
    },
    {
      "epoch": 1.2283464566929134,
      "grad_norm": 2.9080810546875,
      "learning_rate": 2.263937007874016e-05,
      "loss": 0.3565,
      "step": 780
    },
    {
      "epoch": 1.2440944881889764,
      "grad_norm": 3.416236639022827,
      "learning_rate": 2.254488188976378e-05,
      "loss": 0.2772,
      "step": 790
    },
    {
      "epoch": 1.2598425196850394,
      "grad_norm": 6.5986528396606445,
      "learning_rate": 2.24503937007874e-05,
      "loss": 0.3095,
      "step": 800
    },
    {
      "epoch": 1.2755905511811023,
      "grad_norm": 3.579195737838745,
      "learning_rate": 2.2355905511811023e-05,
      "loss": 0.3097,
      "step": 810
    },
    {
      "epoch": 1.2913385826771653,
      "grad_norm": 4.2291178703308105,
      "learning_rate": 2.2261417322834648e-05,
      "loss": 0.3907,
      "step": 820
    },
    {
      "epoch": 1.3070866141732282,
      "grad_norm": 2.421170711517334,
      "learning_rate": 2.216692913385827e-05,
      "loss": 0.309,
      "step": 830
    },
    {
      "epoch": 1.3228346456692912,
      "grad_norm": 2.8303334712982178,
      "learning_rate": 2.207244094488189e-05,
      "loss": 0.3101,
      "step": 840
    },
    {
      "epoch": 1.3385826771653544,
      "grad_norm": 4.434715270996094,
      "learning_rate": 2.197795275590551e-05,
      "loss": 0.303,
      "step": 850
    },
    {
      "epoch": 1.3543307086614174,
      "grad_norm": 1.9131864309310913,
      "learning_rate": 2.1883464566929136e-05,
      "loss": 0.3461,
      "step": 860
    },
    {
      "epoch": 1.3700787401574803,
      "grad_norm": 3.9505558013916016,
      "learning_rate": 2.1788976377952757e-05,
      "loss": 0.3094,
      "step": 870
    },
    {
      "epoch": 1.3858267716535433,
      "grad_norm": 3.518688917160034,
      "learning_rate": 2.1694488188976375e-05,
      "loss": 0.3167,
      "step": 880
    },
    {
      "epoch": 1.4015748031496063,
      "grad_norm": 2.884570598602295,
      "learning_rate": 2.16e-05,
      "loss": 0.4083,
      "step": 890
    },
    {
      "epoch": 1.4173228346456692,
      "grad_norm": 2.0879385471343994,
      "learning_rate": 2.150551181102362e-05,
      "loss": 0.2842,
      "step": 900
    },
    {
      "epoch": 1.4330708661417324,
      "grad_norm": 1.8948850631713867,
      "learning_rate": 2.1411023622047246e-05,
      "loss": 0.27,
      "step": 910
    },
    {
      "epoch": 1.4488188976377954,
      "grad_norm": 4.17876672744751,
      "learning_rate": 2.1316535433070864e-05,
      "loss": 0.3,
      "step": 920
    },
    {
      "epoch": 1.4645669291338583,
      "grad_norm": 1.8892991542816162,
      "learning_rate": 2.122204724409449e-05,
      "loss": 0.2782,
      "step": 930
    },
    {
      "epoch": 1.4803149606299213,
      "grad_norm": 1.765449047088623,
      "learning_rate": 2.112755905511811e-05,
      "loss": 0.2781,
      "step": 940
    },
    {
      "epoch": 1.4960629921259843,
      "grad_norm": 3.335491895675659,
      "learning_rate": 2.1033070866141734e-05,
      "loss": 0.2565,
      "step": 950
    },
    {
      "epoch": 1.5118110236220472,
      "grad_norm": 2.140612840652466,
      "learning_rate": 2.0938582677165352e-05,
      "loss": 0.3359,
      "step": 960
    },
    {
      "epoch": 1.5275590551181102,
      "grad_norm": 2.631239175796509,
      "learning_rate": 2.0844094488188977e-05,
      "loss": 0.3126,
      "step": 970
    },
    {
      "epoch": 1.5433070866141732,
      "grad_norm": 1.5363500118255615,
      "learning_rate": 2.0749606299212598e-05,
      "loss": 0.2394,
      "step": 980
    },
    {
      "epoch": 1.5590551181102361,
      "grad_norm": 2.306417465209961,
      "learning_rate": 2.0655118110236223e-05,
      "loss": 0.3329,
      "step": 990
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 3.1503992080688477,
      "learning_rate": 2.056062992125984e-05,
      "loss": 0.3685,
      "step": 1000
    },
    {
      "epoch": 1.590551181102362,
      "grad_norm": 5.074495792388916,
      "learning_rate": 2.0466141732283465e-05,
      "loss": 0.3543,
      "step": 1010
    },
    {
      "epoch": 1.6062992125984252,
      "grad_norm": 3.20194149017334,
      "learning_rate": 2.0371653543307087e-05,
      "loss": 0.3443,
      "step": 1020
    },
    {
      "epoch": 1.6220472440944882,
      "grad_norm": 2.7572741508483887,
      "learning_rate": 2.027716535433071e-05,
      "loss": 0.2613,
      "step": 1030
    },
    {
      "epoch": 1.6377952755905512,
      "grad_norm": 4.936409950256348,
      "learning_rate": 2.018267716535433e-05,
      "loss": 0.3204,
      "step": 1040
    },
    {
      "epoch": 1.6535433070866141,
      "grad_norm": 2.325500249862671,
      "learning_rate": 2.0088188976377954e-05,
      "loss": 0.2715,
      "step": 1050
    },
    {
      "epoch": 1.6692913385826773,
      "grad_norm": 3.1584532260894775,
      "learning_rate": 1.9993700787401575e-05,
      "loss": 0.2897,
      "step": 1060
    },
    {
      "epoch": 1.6850393700787403,
      "grad_norm": 1.482747197151184,
      "learning_rate": 1.98992125984252e-05,
      "loss": 0.2944,
      "step": 1070
    },
    {
      "epoch": 1.7007874015748032,
      "grad_norm": 3.1203715801239014,
      "learning_rate": 1.9804724409448818e-05,
      "loss": 0.294,
      "step": 1080
    },
    {
      "epoch": 1.7165354330708662,
      "grad_norm": 1.2940689325332642,
      "learning_rate": 1.9710236220472442e-05,
      "loss": 0.2808,
      "step": 1090
    },
    {
      "epoch": 1.7322834645669292,
      "grad_norm": 4.568315505981445,
      "learning_rate": 1.9615748031496064e-05,
      "loss": 0.3072,
      "step": 1100
    },
    {
      "epoch": 1.7480314960629921,
      "grad_norm": 2.8020763397216797,
      "learning_rate": 1.9521259842519685e-05,
      "loss": 0.2678,
      "step": 1110
    },
    {
      "epoch": 1.763779527559055,
      "grad_norm": 3.513540506362915,
      "learning_rate": 1.9426771653543306e-05,
      "loss": 0.3272,
      "step": 1120
    },
    {
      "epoch": 1.779527559055118,
      "grad_norm": 4.649895668029785,
      "learning_rate": 1.9332283464566927e-05,
      "loss": 0.3499,
      "step": 1130
    },
    {
      "epoch": 1.795275590551181,
      "grad_norm": 2.860999584197998,
      "learning_rate": 1.9237795275590552e-05,
      "loss": 0.2725,
      "step": 1140
    },
    {
      "epoch": 1.811023622047244,
      "grad_norm": 1.6819185018539429,
      "learning_rate": 1.9143307086614173e-05,
      "loss": 0.2894,
      "step": 1150
    },
    {
      "epoch": 1.826771653543307,
      "grad_norm": 5.349483489990234,
      "learning_rate": 1.9048818897637795e-05,
      "loss": 0.3411,
      "step": 1160
    },
    {
      "epoch": 1.84251968503937,
      "grad_norm": 3.9752440452575684,
      "learning_rate": 1.8954330708661416e-05,
      "loss": 0.357,
      "step": 1170
    },
    {
      "epoch": 1.858267716535433,
      "grad_norm": 5.915369987487793,
      "learning_rate": 1.885984251968504e-05,
      "loss": 0.3938,
      "step": 1180
    },
    {
      "epoch": 1.874015748031496,
      "grad_norm": 3.301260471343994,
      "learning_rate": 1.8765354330708662e-05,
      "loss": 0.3265,
      "step": 1190
    },
    {
      "epoch": 1.889763779527559,
      "grad_norm": 5.317668437957764,
      "learning_rate": 1.8670866141732283e-05,
      "loss": 0.3277,
      "step": 1200
    },
    {
      "epoch": 1.905511811023622,
      "grad_norm": 3.9323112964630127,
      "learning_rate": 1.8576377952755904e-05,
      "loss": 0.3137,
      "step": 1210
    },
    {
      "epoch": 1.9212598425196852,
      "grad_norm": 3.8394017219543457,
      "learning_rate": 1.848188976377953e-05,
      "loss": 0.3419,
      "step": 1220
    },
    {
      "epoch": 1.9370078740157481,
      "grad_norm": 5.439864635467529,
      "learning_rate": 1.838740157480315e-05,
      "loss": 0.3418,
      "step": 1230
    },
    {
      "epoch": 1.952755905511811,
      "grad_norm": 2.5576841831207275,
      "learning_rate": 1.829291338582677e-05,
      "loss": 0.3424,
      "step": 1240
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 3.666412353515625,
      "learning_rate": 1.8198425196850393e-05,
      "loss": 0.3049,
      "step": 1250
    },
    {
      "epoch": 1.984251968503937,
      "grad_norm": 4.081104278564453,
      "learning_rate": 1.8103937007874017e-05,
      "loss": 0.3052,
      "step": 1260
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.589473724365234,
      "learning_rate": 1.800944881889764e-05,
      "loss": 0.2897,
      "step": 1270
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8769958604376109,
      "eval_loss": 0.30527418851852417,
      "eval_runtime": 13.5833,
      "eval_samples_per_second": 373.474,
      "eval_steps_per_second": 11.706,
      "step": 1270
    },
    {
      "epoch": 2.015748031496063,
      "grad_norm": 2.7334342002868652,
      "learning_rate": 1.791496062992126e-05,
      "loss": 0.2313,
      "step": 1280
    },
    {
      "epoch": 2.031496062992126,
      "grad_norm": 3.065490245819092,
      "learning_rate": 1.782047244094488e-05,
      "loss": 0.3141,
      "step": 1290
    },
    {
      "epoch": 2.047244094488189,
      "grad_norm": 6.157144546508789,
      "learning_rate": 1.7725984251968506e-05,
      "loss": 0.3016,
      "step": 1300
    },
    {
      "epoch": 2.062992125984252,
      "grad_norm": 5.140876770019531,
      "learning_rate": 1.7631496062992127e-05,
      "loss": 0.2631,
      "step": 1310
    },
    {
      "epoch": 2.078740157480315,
      "grad_norm": 4.81197452545166,
      "learning_rate": 1.753700787401575e-05,
      "loss": 0.345,
      "step": 1320
    },
    {
      "epoch": 2.094488188976378,
      "grad_norm": 4.0227131843566895,
      "learning_rate": 1.744251968503937e-05,
      "loss": 0.2843,
      "step": 1330
    },
    {
      "epoch": 2.1102362204724407,
      "grad_norm": 6.015579700469971,
      "learning_rate": 1.7348031496062994e-05,
      "loss": 0.2917,
      "step": 1340
    },
    {
      "epoch": 2.1259842519685037,
      "grad_norm": 3.0768401622772217,
      "learning_rate": 1.7253543307086616e-05,
      "loss": 0.2661,
      "step": 1350
    },
    {
      "epoch": 2.141732283464567,
      "grad_norm": 3.455010414123535,
      "learning_rate": 1.7159055118110233e-05,
      "loss": 0.2579,
      "step": 1360
    },
    {
      "epoch": 2.15748031496063,
      "grad_norm": 3.3570430278778076,
      "learning_rate": 1.7064566929133858e-05,
      "loss": 0.2829,
      "step": 1370
    },
    {
      "epoch": 2.173228346456693,
      "grad_norm": 1.8217567205429077,
      "learning_rate": 1.697007874015748e-05,
      "loss": 0.2751,
      "step": 1380
    },
    {
      "epoch": 2.188976377952756,
      "grad_norm": 2.2634575366973877,
      "learning_rate": 1.6875590551181104e-05,
      "loss": 0.3478,
      "step": 1390
    },
    {
      "epoch": 2.204724409448819,
      "grad_norm": 4.855303764343262,
      "learning_rate": 1.6781102362204722e-05,
      "loss": 0.2911,
      "step": 1400
    },
    {
      "epoch": 2.220472440944882,
      "grad_norm": 1.2821820974349976,
      "learning_rate": 1.6686614173228347e-05,
      "loss": 0.2713,
      "step": 1410
    },
    {
      "epoch": 2.236220472440945,
      "grad_norm": 1.766384243965149,
      "learning_rate": 1.6592125984251968e-05,
      "loss": 0.2904,
      "step": 1420
    },
    {
      "epoch": 2.251968503937008,
      "grad_norm": 2.362726926803589,
      "learning_rate": 1.6497637795275593e-05,
      "loss": 0.267,
      "step": 1430
    },
    {
      "epoch": 2.267716535433071,
      "grad_norm": 3.2041683197021484,
      "learning_rate": 1.640314960629921e-05,
      "loss": 0.269,
      "step": 1440
    },
    {
      "epoch": 2.283464566929134,
      "grad_norm": 2.7983574867248535,
      "learning_rate": 1.6308661417322835e-05,
      "loss": 0.242,
      "step": 1450
    },
    {
      "epoch": 2.2992125984251968,
      "grad_norm": 1.7275561094284058,
      "learning_rate": 1.6214173228346456e-05,
      "loss": 0.3437,
      "step": 1460
    },
    {
      "epoch": 2.3149606299212597,
      "grad_norm": 3.2455527782440186,
      "learning_rate": 1.611968503937008e-05,
      "loss": 0.2892,
      "step": 1470
    },
    {
      "epoch": 2.3307086614173227,
      "grad_norm": 3.1311395168304443,
      "learning_rate": 1.60251968503937e-05,
      "loss": 0.325,
      "step": 1480
    },
    {
      "epoch": 2.3464566929133857,
      "grad_norm": 2.0608413219451904,
      "learning_rate": 1.5930708661417324e-05,
      "loss": 0.3067,
      "step": 1490
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 1.494405746459961,
      "learning_rate": 1.5836220472440945e-05,
      "loss": 0.303,
      "step": 1500
    },
    {
      "epoch": 2.377952755905512,
      "grad_norm": 4.037229061126709,
      "learning_rate": 1.574173228346457e-05,
      "loss": 0.2988,
      "step": 1510
    },
    {
      "epoch": 2.393700787401575,
      "grad_norm": 4.557703971862793,
      "learning_rate": 1.5647244094488187e-05,
      "loss": 0.3071,
      "step": 1520
    },
    {
      "epoch": 2.409448818897638,
      "grad_norm": 2.0623514652252197,
      "learning_rate": 1.5552755905511812e-05,
      "loss": 0.272,
      "step": 1530
    },
    {
      "epoch": 2.425196850393701,
      "grad_norm": 2.07049298286438,
      "learning_rate": 1.5458267716535433e-05,
      "loss": 0.2694,
      "step": 1540
    },
    {
      "epoch": 2.440944881889764,
      "grad_norm": 2.2159311771392822,
      "learning_rate": 1.5363779527559058e-05,
      "loss": 0.2991,
      "step": 1550
    },
    {
      "epoch": 2.456692913385827,
      "grad_norm": 2.824824810028076,
      "learning_rate": 1.5269291338582676e-05,
      "loss": 0.3201,
      "step": 1560
    },
    {
      "epoch": 2.47244094488189,
      "grad_norm": 3.2755167484283447,
      "learning_rate": 1.5174803149606299e-05,
      "loss": 0.2596,
      "step": 1570
    },
    {
      "epoch": 2.4881889763779528,
      "grad_norm": 5.907303333282471,
      "learning_rate": 1.5080314960629922e-05,
      "loss": 0.2891,
      "step": 1580
    },
    {
      "epoch": 2.5039370078740157,
      "grad_norm": 2.2055933475494385,
      "learning_rate": 1.4985826771653543e-05,
      "loss": 0.2736,
      "step": 1590
    },
    {
      "epoch": 2.5196850393700787,
      "grad_norm": 3.0833725929260254,
      "learning_rate": 1.4891338582677166e-05,
      "loss": 0.2566,
      "step": 1600
    },
    {
      "epoch": 2.5354330708661417,
      "grad_norm": 2.423635482788086,
      "learning_rate": 1.4796850393700787e-05,
      "loss": 0.3394,
      "step": 1610
    },
    {
      "epoch": 2.5511811023622046,
      "grad_norm": 2.386946678161621,
      "learning_rate": 1.470236220472441e-05,
      "loss": 0.2941,
      "step": 1620
    },
    {
      "epoch": 2.5669291338582676,
      "grad_norm": 2.7351410388946533,
      "learning_rate": 1.4607874015748032e-05,
      "loss": 0.2843,
      "step": 1630
    },
    {
      "epoch": 2.5826771653543306,
      "grad_norm": 3.4057250022888184,
      "learning_rate": 1.4513385826771655e-05,
      "loss": 0.3354,
      "step": 1640
    },
    {
      "epoch": 2.5984251968503935,
      "grad_norm": 2.2955877780914307,
      "learning_rate": 1.4418897637795276e-05,
      "loss": 0.2457,
      "step": 1650
    },
    {
      "epoch": 2.6141732283464565,
      "grad_norm": 4.1011552810668945,
      "learning_rate": 1.4324409448818899e-05,
      "loss": 0.3565,
      "step": 1660
    },
    {
      "epoch": 2.6299212598425195,
      "grad_norm": 3.4609484672546387,
      "learning_rate": 1.422992125984252e-05,
      "loss": 0.2663,
      "step": 1670
    },
    {
      "epoch": 2.6456692913385824,
      "grad_norm": 4.865339756011963,
      "learning_rate": 1.4135433070866143e-05,
      "loss": 0.3075,
      "step": 1680
    },
    {
      "epoch": 2.661417322834646,
      "grad_norm": 6.343513488769531,
      "learning_rate": 1.4040944881889764e-05,
      "loss": 0.2821,
      "step": 1690
    },
    {
      "epoch": 2.677165354330709,
      "grad_norm": 3.7852835655212402,
      "learning_rate": 1.3946456692913386e-05,
      "loss": 0.3122,
      "step": 1700
    },
    {
      "epoch": 2.6929133858267718,
      "grad_norm": 4.88745641708374,
      "learning_rate": 1.3851968503937007e-05,
      "loss": 0.2676,
      "step": 1710
    },
    {
      "epoch": 2.7086614173228347,
      "grad_norm": 1.7885410785675049,
      "learning_rate": 1.375748031496063e-05,
      "loss": 0.2708,
      "step": 1720
    },
    {
      "epoch": 2.7244094488188977,
      "grad_norm": 3.5381815433502197,
      "learning_rate": 1.3662992125984251e-05,
      "loss": 0.2932,
      "step": 1730
    },
    {
      "epoch": 2.7401574803149606,
      "grad_norm": 2.445164203643799,
      "learning_rate": 1.3568503937007874e-05,
      "loss": 0.2922,
      "step": 1740
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 4.870103359222412,
      "learning_rate": 1.3474015748031495e-05,
      "loss": 0.3172,
      "step": 1750
    },
    {
      "epoch": 2.7716535433070866,
      "grad_norm": 3.3824009895324707,
      "learning_rate": 1.3379527559055118e-05,
      "loss": 0.2832,
      "step": 1760
    },
    {
      "epoch": 2.7874015748031495,
      "grad_norm": 5.19412088394165,
      "learning_rate": 1.328503937007874e-05,
      "loss": 0.3346,
      "step": 1770
    },
    {
      "epoch": 2.8031496062992125,
      "grad_norm": 4.012139320373535,
      "learning_rate": 1.3190551181102362e-05,
      "loss": 0.2836,
      "step": 1780
    },
    {
      "epoch": 2.8188976377952755,
      "grad_norm": 3.677544593811035,
      "learning_rate": 1.3096062992125984e-05,
      "loss": 0.388,
      "step": 1790
    },
    {
      "epoch": 2.8346456692913384,
      "grad_norm": 2.50382137298584,
      "learning_rate": 1.3001574803149607e-05,
      "loss": 0.3228,
      "step": 1800
    },
    {
      "epoch": 2.850393700787402,
      "grad_norm": 3.7788772583007812,
      "learning_rate": 1.2907086614173228e-05,
      "loss": 0.3022,
      "step": 1810
    },
    {
      "epoch": 2.866141732283465,
      "grad_norm": 3.4588305950164795,
      "learning_rate": 1.2812598425196851e-05,
      "loss": 0.3231,
      "step": 1820
    },
    {
      "epoch": 2.8818897637795278,
      "grad_norm": 3.2819015979766846,
      "learning_rate": 1.2718110236220472e-05,
      "loss": 0.2895,
      "step": 1830
    },
    {
      "epoch": 2.8976377952755907,
      "grad_norm": 4.893187522888184,
      "learning_rate": 1.2623622047244095e-05,
      "loss": 0.2769,
      "step": 1840
    },
    {
      "epoch": 2.9133858267716537,
      "grad_norm": 4.39833927154541,
      "learning_rate": 1.2529133858267716e-05,
      "loss": 0.32,
      "step": 1850
    },
    {
      "epoch": 2.9291338582677167,
      "grad_norm": 1.8671250343322754,
      "learning_rate": 1.243464566929134e-05,
      "loss": 0.2866,
      "step": 1860
    },
    {
      "epoch": 2.9448818897637796,
      "grad_norm": 5.061060428619385,
      "learning_rate": 1.234015748031496e-05,
      "loss": 0.2974,
      "step": 1870
    },
    {
      "epoch": 2.9606299212598426,
      "grad_norm": 2.9508070945739746,
      "learning_rate": 1.2245669291338584e-05,
      "loss": 0.305,
      "step": 1880
    },
    {
      "epoch": 2.9763779527559056,
      "grad_norm": 5.03820276260376,
      "learning_rate": 1.2151181102362205e-05,
      "loss": 0.2886,
      "step": 1890
    },
    {
      "epoch": 2.9921259842519685,
      "grad_norm": 1.3256044387817383,
      "learning_rate": 1.2056692913385828e-05,
      "loss": 0.2741,
      "step": 1900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8815296668637886,
      "eval_loss": 0.2936955690383911,
      "eval_runtime": 13.5861,
      "eval_samples_per_second": 373.395,
      "eval_steps_per_second": 11.703,
      "step": 1905
    },
    {
      "epoch": 3.0078740157480315,
      "grad_norm": 2.859569549560547,
      "learning_rate": 1.1962204724409449e-05,
      "loss": 0.3354,
      "step": 1910
    },
    {
      "epoch": 3.0236220472440944,
      "grad_norm": 2.9717636108398438,
      "learning_rate": 1.1867716535433072e-05,
      "loss": 0.3279,
      "step": 1920
    },
    {
      "epoch": 3.0393700787401574,
      "grad_norm": 5.5456223487854,
      "learning_rate": 1.1773228346456693e-05,
      "loss": 0.2449,
      "step": 1930
    },
    {
      "epoch": 3.0551181102362204,
      "grad_norm": 2.2646262645721436,
      "learning_rate": 1.1678740157480315e-05,
      "loss": 0.307,
      "step": 1940
    },
    {
      "epoch": 3.0708661417322833,
      "grad_norm": 2.5120322704315186,
      "learning_rate": 1.1584251968503936e-05,
      "loss": 0.3016,
      "step": 1950
    },
    {
      "epoch": 3.0866141732283463,
      "grad_norm": 2.6964120864868164,
      "learning_rate": 1.1489763779527559e-05,
      "loss": 0.2928,
      "step": 1960
    },
    {
      "epoch": 3.1023622047244093,
      "grad_norm": 2.3144781589508057,
      "learning_rate": 1.139527559055118e-05,
      "loss": 0.2906,
      "step": 1970
    },
    {
      "epoch": 3.1181102362204722,
      "grad_norm": 2.451228141784668,
      "learning_rate": 1.1300787401574803e-05,
      "loss": 0.2877,
      "step": 1980
    },
    {
      "epoch": 3.1338582677165356,
      "grad_norm": 3.281214475631714,
      "learning_rate": 1.1206299212598424e-05,
      "loss": 0.2641,
      "step": 1990
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 2.696010112762451,
      "learning_rate": 1.1111811023622047e-05,
      "loss": 0.311,
      "step": 2000
    },
    {
      "epoch": 3.1653543307086616,
      "grad_norm": 3.2701985836029053,
      "learning_rate": 1.1017322834645669e-05,
      "loss": 0.2597,
      "step": 2010
    },
    {
      "epoch": 3.1811023622047245,
      "grad_norm": 5.283978462219238,
      "learning_rate": 1.0922834645669292e-05,
      "loss": 0.2768,
      "step": 2020
    },
    {
      "epoch": 3.1968503937007875,
      "grad_norm": 2.7128522396087646,
      "learning_rate": 1.0828346456692913e-05,
      "loss": 0.3143,
      "step": 2030
    },
    {
      "epoch": 3.2125984251968505,
      "grad_norm": 3.4167773723602295,
      "learning_rate": 1.0733858267716536e-05,
      "loss": 0.2899,
      "step": 2040
    },
    {
      "epoch": 3.2283464566929134,
      "grad_norm": 1.696265459060669,
      "learning_rate": 1.0639370078740157e-05,
      "loss": 0.2592,
      "step": 2050
    },
    {
      "epoch": 3.2440944881889764,
      "grad_norm": 3.124462842941284,
      "learning_rate": 1.054488188976378e-05,
      "loss": 0.2996,
      "step": 2060
    },
    {
      "epoch": 3.2598425196850394,
      "grad_norm": 3.4730780124664307,
      "learning_rate": 1.0450393700787401e-05,
      "loss": 0.2373,
      "step": 2070
    },
    {
      "epoch": 3.2755905511811023,
      "grad_norm": 3.473768949508667,
      "learning_rate": 1.0355905511811024e-05,
      "loss": 0.2667,
      "step": 2080
    },
    {
      "epoch": 3.2913385826771653,
      "grad_norm": 2.7013723850250244,
      "learning_rate": 1.0261417322834646e-05,
      "loss": 0.3165,
      "step": 2090
    },
    {
      "epoch": 3.3070866141732282,
      "grad_norm": 6.392555236816406,
      "learning_rate": 1.0166929133858269e-05,
      "loss": 0.2525,
      "step": 2100
    },
    {
      "epoch": 3.322834645669291,
      "grad_norm": 3.1959404945373535,
      "learning_rate": 1.007244094488189e-05,
      "loss": 0.2568,
      "step": 2110
    },
    {
      "epoch": 3.338582677165354,
      "grad_norm": 1.2710957527160645,
      "learning_rate": 9.977952755905513e-06,
      "loss": 0.2526,
      "step": 2120
    },
    {
      "epoch": 3.354330708661417,
      "grad_norm": 4.7501220703125,
      "learning_rate": 9.883464566929134e-06,
      "loss": 0.2768,
      "step": 2130
    },
    {
      "epoch": 3.3700787401574805,
      "grad_norm": 3.9923155307769775,
      "learning_rate": 9.788976377952757e-06,
      "loss": 0.2811,
      "step": 2140
    },
    {
      "epoch": 3.3858267716535435,
      "grad_norm": 2.4158496856689453,
      "learning_rate": 9.694488188976378e-06,
      "loss": 0.2759,
      "step": 2150
    },
    {
      "epoch": 3.4015748031496065,
      "grad_norm": 2.3834493160247803,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.2372,
      "step": 2160
    },
    {
      "epoch": 3.4173228346456694,
      "grad_norm": 6.411980628967285,
      "learning_rate": 9.50551181102362e-06,
      "loss": 0.2151,
      "step": 2170
    },
    {
      "epoch": 3.4330708661417324,
      "grad_norm": 4.475795745849609,
      "learning_rate": 9.411023622047244e-06,
      "loss": 0.2628,
      "step": 2180
    },
    {
      "epoch": 3.4488188976377954,
      "grad_norm": 2.075883626937866,
      "learning_rate": 9.316535433070865e-06,
      "loss": 0.265,
      "step": 2190
    },
    {
      "epoch": 3.4645669291338583,
      "grad_norm": 3.747711181640625,
      "learning_rate": 9.222047244094488e-06,
      "loss": 0.2662,
      "step": 2200
    },
    {
      "epoch": 3.4803149606299213,
      "grad_norm": 6.599269390106201,
      "learning_rate": 9.12755905511811e-06,
      "loss": 0.335,
      "step": 2210
    },
    {
      "epoch": 3.4960629921259843,
      "grad_norm": 4.126960277557373,
      "learning_rate": 9.033070866141732e-06,
      "loss": 0.25,
      "step": 2220
    },
    {
      "epoch": 3.5118110236220472,
      "grad_norm": 3.0943219661712646,
      "learning_rate": 8.938582677165354e-06,
      "loss": 0.3034,
      "step": 2230
    },
    {
      "epoch": 3.52755905511811,
      "grad_norm": 4.89608907699585,
      "learning_rate": 8.844094488188977e-06,
      "loss": 0.293,
      "step": 2240
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 3.114853620529175,
      "learning_rate": 8.749606299212598e-06,
      "loss": 0.2481,
      "step": 2250
    },
    {
      "epoch": 3.559055118110236,
      "grad_norm": 5.477428436279297,
      "learning_rate": 8.65511811023622e-06,
      "loss": 0.3142,
      "step": 2260
    },
    {
      "epoch": 3.574803149606299,
      "grad_norm": 2.059633731842041,
      "learning_rate": 8.560629921259842e-06,
      "loss": 0.2836,
      "step": 2270
    },
    {
      "epoch": 3.590551181102362,
      "grad_norm": 3.9358291625976562,
      "learning_rate": 8.466141732283465e-06,
      "loss": 0.2817,
      "step": 2280
    },
    {
      "epoch": 3.606299212598425,
      "grad_norm": 2.149245262145996,
      "learning_rate": 8.371653543307086e-06,
      "loss": 0.2611,
      "step": 2290
    },
    {
      "epoch": 3.622047244094488,
      "grad_norm": 3.072930097579956,
      "learning_rate": 8.27716535433071e-06,
      "loss": 0.3149,
      "step": 2300
    },
    {
      "epoch": 3.637795275590551,
      "grad_norm": 4.9943528175354,
      "learning_rate": 8.18267716535433e-06,
      "loss": 0.3293,
      "step": 2310
    },
    {
      "epoch": 3.653543307086614,
      "grad_norm": 4.236912250518799,
      "learning_rate": 8.088188976377953e-06,
      "loss": 0.334,
      "step": 2320
    },
    {
      "epoch": 3.6692913385826773,
      "grad_norm": 2.778269052505493,
      "learning_rate": 7.993700787401575e-06,
      "loss": 0.3088,
      "step": 2330
    },
    {
      "epoch": 3.6850393700787403,
      "grad_norm": 4.58181095123291,
      "learning_rate": 7.899212598425198e-06,
      "loss": 0.2869,
      "step": 2340
    },
    {
      "epoch": 3.7007874015748032,
      "grad_norm": 4.795485019683838,
      "learning_rate": 7.804724409448819e-06,
      "loss": 0.3409,
      "step": 2350
    },
    {
      "epoch": 3.716535433070866,
      "grad_norm": 2.424551010131836,
      "learning_rate": 7.710236220472442e-06,
      "loss": 0.3092,
      "step": 2360
    },
    {
      "epoch": 3.732283464566929,
      "grad_norm": 2.7391514778137207,
      "learning_rate": 7.615748031496062e-06,
      "loss": 0.2887,
      "step": 2370
    },
    {
      "epoch": 3.748031496062992,
      "grad_norm": 2.514704465866089,
      "learning_rate": 7.521259842519685e-06,
      "loss": 0.3586,
      "step": 2380
    },
    {
      "epoch": 3.763779527559055,
      "grad_norm": 2.914546012878418,
      "learning_rate": 7.4267716535433074e-06,
      "loss": 0.2423,
      "step": 2390
    },
    {
      "epoch": 3.779527559055118,
      "grad_norm": 3.127040386199951,
      "learning_rate": 7.3322834645669296e-06,
      "loss": 0.2956,
      "step": 2400
    },
    {
      "epoch": 3.795275590551181,
      "grad_norm": 2.6330087184906006,
      "learning_rate": 7.237795275590552e-06,
      "loss": 0.2874,
      "step": 2410
    },
    {
      "epoch": 3.811023622047244,
      "grad_norm": 1.7983187437057495,
      "learning_rate": 7.143307086614174e-06,
      "loss": 0.2574,
      "step": 2420
    },
    {
      "epoch": 3.826771653543307,
      "grad_norm": 2.9603493213653564,
      "learning_rate": 7.048818897637796e-06,
      "loss": 0.1942,
      "step": 2430
    },
    {
      "epoch": 3.84251968503937,
      "grad_norm": 2.3734939098358154,
      "learning_rate": 6.954330708661418e-06,
      "loss": 0.3027,
      "step": 2440
    },
    {
      "epoch": 3.8582677165354333,
      "grad_norm": 3.045105457305908,
      "learning_rate": 6.85984251968504e-06,
      "loss": 0.3247,
      "step": 2450
    },
    {
      "epoch": 3.8740157480314963,
      "grad_norm": 3.2516775131225586,
      "learning_rate": 6.765354330708661e-06,
      "loss": 0.3202,
      "step": 2460
    },
    {
      "epoch": 3.8897637795275593,
      "grad_norm": 1.7774126529693604,
      "learning_rate": 6.6708661417322835e-06,
      "loss": 0.2455,
      "step": 2470
    },
    {
      "epoch": 3.905511811023622,
      "grad_norm": 3.816754102706909,
      "learning_rate": 6.576377952755906e-06,
      "loss": 0.2712,
      "step": 2480
    },
    {
      "epoch": 3.921259842519685,
      "grad_norm": 2.713979959487915,
      "learning_rate": 6.481889763779528e-06,
      "loss": 0.266,
      "step": 2490
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 3.093611478805542,
      "learning_rate": 6.38740157480315e-06,
      "loss": 0.2724,
      "step": 2500
    },
    {
      "epoch": 3.952755905511811,
      "grad_norm": 2.1340088844299316,
      "learning_rate": 6.292913385826772e-06,
      "loss": 0.2752,
      "step": 2510
    },
    {
      "epoch": 3.968503937007874,
      "grad_norm": 2.8348684310913086,
      "learning_rate": 6.198425196850394e-06,
      "loss": 0.2376,
      "step": 2520
    },
    {
      "epoch": 3.984251968503937,
      "grad_norm": 1.9444348812103271,
      "learning_rate": 6.103937007874016e-06,
      "loss": 0.2567,
      "step": 2530
    },
    {
      "epoch": 4.0,
      "grad_norm": 7.8074727058410645,
      "learning_rate": 6.009448818897638e-06,
      "loss": 0.3424,
      "step": 2540
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8872462054011433,
      "eval_loss": 0.2798205316066742,
      "eval_runtime": 13.5678,
      "eval_samples_per_second": 373.9,
      "eval_steps_per_second": 11.719,
      "step": 2540
    },
    {
      "epoch": 4.015748031496063,
      "grad_norm": 5.306019306182861,
      "learning_rate": 5.9149606299212605e-06,
      "loss": 0.2331,
      "step": 2550
    },
    {
      "epoch": 4.031496062992126,
      "grad_norm": 2.284026622772217,
      "learning_rate": 5.820472440944883e-06,
      "loss": 0.2881,
      "step": 2560
    },
    {
      "epoch": 4.047244094488189,
      "grad_norm": 2.9200515747070312,
      "learning_rate": 5.725984251968505e-06,
      "loss": 0.3046,
      "step": 2570
    },
    {
      "epoch": 4.062992125984252,
      "grad_norm": 3.4211349487304688,
      "learning_rate": 5.631496062992126e-06,
      "loss": 0.2921,
      "step": 2580
    },
    {
      "epoch": 4.078740157480315,
      "grad_norm": 1.9274306297302246,
      "learning_rate": 5.537007874015748e-06,
      "loss": 0.2884,
      "step": 2590
    },
    {
      "epoch": 4.094488188976378,
      "grad_norm": 4.39193058013916,
      "learning_rate": 5.44251968503937e-06,
      "loss": 0.2311,
      "step": 2600
    },
    {
      "epoch": 4.110236220472441,
      "grad_norm": 1.925081729888916,
      "learning_rate": 5.348031496062992e-06,
      "loss": 0.3006,
      "step": 2610
    },
    {
      "epoch": 4.125984251968504,
      "grad_norm": 3.492650270462036,
      "learning_rate": 5.2535433070866145e-06,
      "loss": 0.2355,
      "step": 2620
    },
    {
      "epoch": 4.141732283464567,
      "grad_norm": 2.908376932144165,
      "learning_rate": 5.159055118110237e-06,
      "loss": 0.3428,
      "step": 2630
    },
    {
      "epoch": 4.15748031496063,
      "grad_norm": 3.5317165851593018,
      "learning_rate": 5.064566929133859e-06,
      "loss": 0.3025,
      "step": 2640
    },
    {
      "epoch": 4.173228346456693,
      "grad_norm": 1.928309679031372,
      "learning_rate": 4.970078740157481e-06,
      "loss": 0.2391,
      "step": 2650
    },
    {
      "epoch": 4.188976377952756,
      "grad_norm": 3.7136199474334717,
      "learning_rate": 4.875590551181103e-06,
      "loss": 0.2709,
      "step": 2660
    },
    {
      "epoch": 4.2047244094488185,
      "grad_norm": 1.8628968000411987,
      "learning_rate": 4.781102362204725e-06,
      "loss": 0.2733,
      "step": 2670
    },
    {
      "epoch": 4.2204724409448815,
      "grad_norm": 1.9517402648925781,
      "learning_rate": 4.686614173228347e-06,
      "loss": 0.2541,
      "step": 2680
    },
    {
      "epoch": 4.2362204724409445,
      "grad_norm": 4.605186939239502,
      "learning_rate": 4.592125984251969e-06,
      "loss": 0.267,
      "step": 2690
    },
    {
      "epoch": 4.251968503937007,
      "grad_norm": 3.3277571201324463,
      "learning_rate": 4.4976377952755906e-06,
      "loss": 0.286,
      "step": 2700
    },
    {
      "epoch": 4.267716535433071,
      "grad_norm": 4.4630351066589355,
      "learning_rate": 4.403149606299213e-06,
      "loss": 0.2963,
      "step": 2710
    },
    {
      "epoch": 4.283464566929134,
      "grad_norm": 2.545128107070923,
      "learning_rate": 4.308661417322835e-06,
      "loss": 0.2426,
      "step": 2720
    },
    {
      "epoch": 4.299212598425197,
      "grad_norm": 3.065584659576416,
      "learning_rate": 4.214173228346457e-06,
      "loss": 0.2623,
      "step": 2730
    },
    {
      "epoch": 4.31496062992126,
      "grad_norm": 4.839801788330078,
      "learning_rate": 4.119685039370079e-06,
      "loss": 0.2258,
      "step": 2740
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 1.7947531938552856,
      "learning_rate": 4.025196850393701e-06,
      "loss": 0.2683,
      "step": 2750
    },
    {
      "epoch": 4.346456692913386,
      "grad_norm": 1.476177453994751,
      "learning_rate": 3.930708661417323e-06,
      "loss": 0.2402,
      "step": 2760
    },
    {
      "epoch": 4.362204724409449,
      "grad_norm": 1.5411325693130493,
      "learning_rate": 3.836220472440945e-06,
      "loss": 0.2778,
      "step": 2770
    },
    {
      "epoch": 4.377952755905512,
      "grad_norm": 2.212502956390381,
      "learning_rate": 3.741732283464567e-06,
      "loss": 0.3266,
      "step": 2780
    },
    {
      "epoch": 4.393700787401575,
      "grad_norm": 2.5666778087615967,
      "learning_rate": 3.6472440944881888e-06,
      "loss": 0.2319,
      "step": 2790
    },
    {
      "epoch": 4.409448818897638,
      "grad_norm": 3.3040225505828857,
      "learning_rate": 3.552755905511811e-06,
      "loss": 0.2434,
      "step": 2800
    },
    {
      "epoch": 4.425196850393701,
      "grad_norm": 1.4813001155853271,
      "learning_rate": 3.458267716535433e-06,
      "loss": 0.289,
      "step": 2810
    },
    {
      "epoch": 4.440944881889764,
      "grad_norm": 2.180420398712158,
      "learning_rate": 3.363779527559055e-06,
      "loss": 0.2598,
      "step": 2820
    },
    {
      "epoch": 4.456692913385827,
      "grad_norm": 4.507220268249512,
      "learning_rate": 3.2692913385826773e-06,
      "loss": 0.268,
      "step": 2830
    },
    {
      "epoch": 4.47244094488189,
      "grad_norm": 4.001136779785156,
      "learning_rate": 3.1748031496062994e-06,
      "loss": 0.2879,
      "step": 2840
    },
    {
      "epoch": 4.488188976377953,
      "grad_norm": 2.997821092605591,
      "learning_rate": 3.080314960629921e-06,
      "loss": 0.3211,
      "step": 2850
    },
    {
      "epoch": 4.503937007874016,
      "grad_norm": 5.294586181640625,
      "learning_rate": 2.985826771653543e-06,
      "loss": 0.2405,
      "step": 2860
    },
    {
      "epoch": 4.519685039370079,
      "grad_norm": 1.8298155069351196,
      "learning_rate": 2.8913385826771653e-06,
      "loss": 0.283,
      "step": 2870
    },
    {
      "epoch": 4.535433070866142,
      "grad_norm": 2.540574789047241,
      "learning_rate": 2.7968503937007874e-06,
      "loss": 0.2478,
      "step": 2880
    },
    {
      "epoch": 4.551181102362205,
      "grad_norm": 2.652632474899292,
      "learning_rate": 2.7023622047244095e-06,
      "loss": 0.2515,
      "step": 2890
    },
    {
      "epoch": 4.566929133858268,
      "grad_norm": 4.907768249511719,
      "learning_rate": 2.6078740157480312e-06,
      "loss": 0.2573,
      "step": 2900
    },
    {
      "epoch": 4.582677165354331,
      "grad_norm": 3.0107898712158203,
      "learning_rate": 2.5133858267716533e-06,
      "loss": 0.2379,
      "step": 2910
    },
    {
      "epoch": 4.5984251968503935,
      "grad_norm": 2.3034074306488037,
      "learning_rate": 2.4188976377952755e-06,
      "loss": 0.2854,
      "step": 2920
    },
    {
      "epoch": 4.6141732283464565,
      "grad_norm": 1.8547807931900024,
      "learning_rate": 2.3244094488188976e-06,
      "loss": 0.2935,
      "step": 2930
    },
    {
      "epoch": 4.6299212598425195,
      "grad_norm": 3.878507614135742,
      "learning_rate": 2.2299212598425197e-06,
      "loss": 0.2629,
      "step": 2940
    },
    {
      "epoch": 4.645669291338582,
      "grad_norm": 4.229751110076904,
      "learning_rate": 2.135433070866142e-06,
      "loss": 0.2666,
      "step": 2950
    },
    {
      "epoch": 4.661417322834645,
      "grad_norm": 1.2847737073898315,
      "learning_rate": 2.0409448818897635e-06,
      "loss": 0.2478,
      "step": 2960
    },
    {
      "epoch": 4.677165354330708,
      "grad_norm": 2.1723296642303467,
      "learning_rate": 1.9464566929133856e-06,
      "loss": 0.2109,
      "step": 2970
    },
    {
      "epoch": 4.692913385826771,
      "grad_norm": 5.939192771911621,
      "learning_rate": 1.851968503937008e-06,
      "loss": 0.3271,
      "step": 2980
    },
    {
      "epoch": 4.708661417322834,
      "grad_norm": 6.603466033935547,
      "learning_rate": 1.75748031496063e-06,
      "loss": 0.2672,
      "step": 2990
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 2.296995162963867,
      "learning_rate": 1.6629921259842522e-06,
      "loss": 0.2558,
      "step": 3000
    },
    {
      "epoch": 4.740157480314961,
      "grad_norm": 4.087570667266846,
      "learning_rate": 1.5685039370078741e-06,
      "loss": 0.2352,
      "step": 3010
    },
    {
      "epoch": 4.755905511811024,
      "grad_norm": 5.363421440124512,
      "learning_rate": 1.474015748031496e-06,
      "loss": 0.2954,
      "step": 3020
    },
    {
      "epoch": 4.771653543307087,
      "grad_norm": 3.840733051300049,
      "learning_rate": 1.3795275590551181e-06,
      "loss": 0.3098,
      "step": 3030
    },
    {
      "epoch": 4.78740157480315,
      "grad_norm": 5.171510696411133,
      "learning_rate": 1.28503937007874e-06,
      "loss": 0.2989,
      "step": 3040
    },
    {
      "epoch": 4.803149606299213,
      "grad_norm": 6.08001184463501,
      "learning_rate": 1.1905511811023622e-06,
      "loss": 0.2497,
      "step": 3050
    },
    {
      "epoch": 4.818897637795276,
      "grad_norm": 3.4179787635803223,
      "learning_rate": 1.0960629921259843e-06,
      "loss": 0.2481,
      "step": 3060
    },
    {
      "epoch": 4.834645669291339,
      "grad_norm": 4.185112953186035,
      "learning_rate": 1.0015748031496062e-06,
      "loss": 0.3032,
      "step": 3070
    },
    {
      "epoch": 4.850393700787402,
      "grad_norm": 1.7990108728408813,
      "learning_rate": 9.070866141732284e-07,
      "loss": 0.286,
      "step": 3080
    },
    {
      "epoch": 4.866141732283465,
      "grad_norm": 4.313209533691406,
      "learning_rate": 8.125984251968504e-07,
      "loss": 0.2469,
      "step": 3090
    },
    {
      "epoch": 4.881889763779528,
      "grad_norm": 2.7549450397491455,
      "learning_rate": 7.181102362204724e-07,
      "loss": 0.2588,
      "step": 3100
    },
    {
      "epoch": 4.897637795275591,
      "grad_norm": 2.426729202270508,
      "learning_rate": 6.236220472440945e-07,
      "loss": 0.2795,
      "step": 3110
    },
    {
      "epoch": 4.913385826771654,
      "grad_norm": 2.913912057876587,
      "learning_rate": 5.291338582677166e-07,
      "loss": 0.2782,
      "step": 3120
    },
    {
      "epoch": 4.929133858267717,
      "grad_norm": 4.784384727478027,
      "learning_rate": 4.3464566929133863e-07,
      "loss": 0.241,
      "step": 3130
    },
    {
      "epoch": 4.94488188976378,
      "grad_norm": 1.517940878868103,
      "learning_rate": 3.4015748031496064e-07,
      "loss": 0.2414,
      "step": 3140
    },
    {
      "epoch": 4.960629921259843,
      "grad_norm": 3.841648817062378,
      "learning_rate": 2.456692913385827e-07,
      "loss": 0.3166,
      "step": 3150
    },
    {
      "epoch": 4.9763779527559056,
      "grad_norm": 3.64713191986084,
      "learning_rate": 1.5118110236220472e-07,
      "loss": 0.2664,
      "step": 3160
    },
    {
      "epoch": 4.9921259842519685,
      "grad_norm": 4.321435928344727,
      "learning_rate": 5.6692913385826775e-08,
      "loss": 0.2355,
      "step": 3170
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8876404494382022,
      "eval_loss": 0.27909475564956665,
      "eval_runtime": 13.5782,
      "eval_samples_per_second": 373.614,
      "eval_steps_per_second": 11.71,
      "step": 3175
    }
  ],
  "logging_steps": 10,
  "max_steps": 3175,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.743156387713024e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
